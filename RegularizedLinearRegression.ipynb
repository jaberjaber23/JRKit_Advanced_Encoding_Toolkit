{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f1f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RegularizedLinearRegression:\n",
    "    \"\"\"\n",
    "    A class for performing Regularized Linear Regression.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    reg_lambda: float (default=0.0)\n",
    "        The regularization term to avoid overfitting.\n",
    "        \n",
    "    Attributes:\n",
    "    ----------\n",
    "    weights: ndarray\n",
    "        The weights learned by the model during training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, reg_lambda=0.0):\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the Regularized Linear Regression model on the input data X and target variable y.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        X: ndarray, shape (n_samples, n_features)\n",
    "            The input training data.\n",
    "        y: ndarray, shape (n_samples,)\n",
    "            The target variable.\n",
    "            \n",
    "        Returns:\n",
    "        -------\n",
    "        self: object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        \n",
    "        identity = np.identity(n_features)\n",
    "        identity[0, 0] = 0  # Set the first element to zero to exclude the bias term from regularization\n",
    "        \n",
    "        X_transpose = np.transpose(X)\n",
    "        regularization = self.reg_lambda * identity\n",
    "        \n",
    "        inverse = np.linalg.inv(np.dot(X_transpose, X) + regularization)\n",
    "        self.weights = np.dot(np.dot(inverse, X_transpose), y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the target variable for a new set of input data X.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        X: ndarray, shape (n_samples, n_features)\n",
    "            The input data to make predictions on.\n",
    "            \n",
    "        Returns:\n",
    "        -------\n",
    "        y_pred: ndarray, shape (n_samples,)\n",
    "            The predicted target variable.\n",
    "        \"\"\"\n",
    "        y_pred = np.dot(X, self.weights)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35e95428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "class RegularizedLinearRegressionEncoder:\n",
    "    \n",
    "    \"\"\"A class for encoding categorical variables using a regularized linear regression model.\n",
    "    \n",
    "    Attributes:\n",
    "        alpha (float, optional): The regularization strength; must be a positive float. The smaller the value, the stronger the regularization. Defaults to 0.1.\n",
    "        l1_ratio (float, optional): The balance between L1 and L2 regularization. Must be between 0 and 1. The closer to 0, the more L2 regularization is applied. The closer to 1, the more L1 regularization is applied. Defaults to 0.5.\n",
    "        categories_ (List[str]): A list of the categories in the data. Set after calling the `fit` method.\n",
    "        encoded_columns_ (np.ndarray): A 2D numpy array with the encoded data. Set after calling the `transform` method.\n",
    "        weights_ (np.ndarray): A 1D numpy array with the weights for each category. Set after calling the `fit` method.\n",
    "        intercept_ (float): The intercept value for the linear regression model. Set after calling the `fit` method.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.1, l1_ratio=0.5):\n",
    "        \n",
    "        \"\"\"Initialize the RegularizedLinearRegressionEncoder object.\n",
    "        \n",
    "        Args:\n",
    "            alpha (float, optional): The regularization strength; must be a positive float. The smaller the value, the stronger the regularization. Defaults to 0.1.\n",
    "            l1_ratio (float, optional): The balance between L1 and L2 regularization. Must be between 0 and 1. The closer to 0, the more L2 regularization is applied. The closer to 1, the more L1 regularization is applied. Defaults to 0.5.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.categories_ = None\n",
    "        self.encoded_columns_ = None\n",
    "        self.weights_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the encoder to the input data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples,)\n",
    "            The categorical data to be encoded.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "            \n",
    "        # Get the unique categories in the input data\n",
    "        self.categories_ = list(set(X))\n",
    "        \n",
    "        # Encode the categories as one-hot vectors\n",
    "        X_encoded = self.onehot_encode(X)\n",
    "        \n",
    "        # Add a column of ones to X_encoded to account for the intercept term\n",
    "        X_encoded = np.hstack((np.ones((X_encoded.shape[0], 1)), X_encoded))\n",
    "        \n",
    "        # Calculate the regularization term\n",
    "        reg_term = self.alpha * self.l1_ratio * np.ones(X_encoded.shape[1])\n",
    "        \n",
    "        # Use ridge regression to calculate the weights\n",
    "        identity = np.identity(X_encoded.shape[1])\n",
    "        identity[0, 0] = 0 # Do not regularize the intercept term\n",
    "        self.weights_ = np.dot(inv(np.dot(X_encoded.T, X_encoded) + np.dot(reg_term, reg_term.T)), np.dot(X_encoded.T, y))\n",
    "        \n",
    "        # Save the encoded column names for later use\n",
    "        self.encoded_columns_ = [\"x_{}_{}\".format(i, c) for i, c in enumerate(self.categories_)]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Encode the input categorical data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples,)\n",
    "            The categorical data to be encoded.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        encoded : array-like, shape (n_samples,)\n",
    "            The encoded target values.\n",
    "        \"\"\"\n",
    "            \n",
    "        # Encode the categories as one-hot vectors\n",
    "        X_encoded = self.onehot_encode(X)\n",
    "        \n",
    "        # Add a column of ones to X_encoded to account for the intercept term\n",
    "        X_encoded = np.hstack((np.ones((X_encoded.shape[0], 1)), X_encoded))\n",
    "        \n",
    "        # Calculate the predicted target values\n",
    "        return np.dot(X_encoded, self.weights_)\n",
    "    \n",
    "    def onehot_encode(self, X):\n",
    "        \"\"\"\n",
    "        Encode categorical data as one-hot vectors.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples,)\n",
    "            Input data, where n_samples is the number of samples.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X_encoded : array-like, shape (n_samples, n_features)\n",
    "            Encoded input data, where n_features is the number of features.\n",
    "        \"\"\"\n",
    "        X_encoded = np.zeros((len(X), len(self.categories_)))\n",
    "        for i, x in enumerate(X):\n",
    "            X_encoded[i, self.categories_.index(x)] = 1\n",
    "        return X_encoded\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the encoding model to the input data and return the transformed data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples,)\n",
    "            Input data, where n_samples is the number of samples.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Target values.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X_encoded : array-like, shape (n_samples, n_features)\n",
    "            Encoded input data, where n_features is the number of features.\n",
    "        \"\"\"\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "986dc286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "['A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D']\n",
      "\n",
      "Encoded data:\n",
      "[11.6828074  11.82642331 13.39411454 14.29206119 11.6828074  11.82642331\n",
      " 13.39411454 14.29206119 11.6828074  11.82642331 13.39411454 14.29206119\n",
      " 11.6828074  11.82642331 13.39411454 14.29206119 11.6828074  11.82642331\n",
      " 13.39411454 14.29206119 11.6828074  11.82642331 13.39411454 14.29206119\n",
      " 11.6828074  11.82642331 13.39411454 14.29206119 11.6828074  11.82642331\n",
      " 13.39411454 14.29206119 11.6828074  11.82642331 13.39411454 14.29206119]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "X = [\"A\", \"B\", \"C\", \"D\", \"A\", \"B\", \"C\", \"D\", \"A\", \"B\", \"C\", \"D\"] * 3\n",
    "y = np.random.normal(10, 1, len(X)) + [1, 2, 3, 4] * 9\n",
    "\n",
    "# Fit the encoder to the data\n",
    "encoder = RegularizedLinearRegressionEncoder()\n",
    "encoder.fit(X, y)\n",
    "\n",
    "# Transform the data\n",
    "encoded_y = encoder.transform(X)\n",
    "\n",
    "# Print the original data and the encoded data\n",
    "print(\"Original data:\")\n",
    "print(X)\n",
    "print(\"\\nEncoded data:\")\n",
    "print(encoded_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e115d589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
